{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie reviews\n",
    "\n",
    "This notebook takes you though a complete iteration of Machine Learning Assignment 1 - Movie reviews. The assignment details (including links to download the data) can be found [here](https://docs.google.com/document/d/1WGYw99e5q6j5V0Zrf2HveagU6URt_kVvdR8B9HYQ99E/edit?usp=sharing). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports and magic commands\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from my_measures import BinaryClassificationPerformance\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!!! Make sure you are using `BinaryClassificationPerformance` v1.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class BinaryClassificationPerformance in module my_measures:\n",
      "\n",
      "class BinaryClassificationPerformance(builtins.object)\n",
      " |  BinaryClassificationPerformance(predictions, labels, desc, probabilities=None)\n",
      " |  \n",
      " |  Performance measures to evaluate the fit of a binary classification model, v1.02\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, predictions, labels, desc, probabilities=None)\n",
      " |      Initialize attributes: predictions-vector of predicted values for Y, labels-vector of labels for Y\n",
      " |  \n",
      " |  compute_measures(self)\n",
      " |      Compute performance measures defined by Flach p. 57\n",
      " |  \n",
      " |  img_indices(self)\n",
      " |      Get the indices of true and false positives to be able to locate the corresponding images in a list of image names\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for feature building and extraction on natural language data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw data and completes all preprocessing required before model fits\n",
    "def process_raw_data(fn, my_random_seed, test=False):\n",
    "    # read and summarize data\n",
    "    movie_data = pd.read_csv(fn, sep='\\t')\n",
    "    print(\"movie_data is:\", type(movie_data))\n",
    "    print(\"movie_data has\", movie_data.shape[0], \"rows and\", movie_data.shape[1], \"columns\", \"\\n\")\n",
    "    print(\"the data types for each of the columns in movie_data:\")\n",
    "    print(movie_data.dtypes, \"\\n\")\n",
    "    print(\"the first 10 rows in movie_data:\")\n",
    "    print(movie_data.head(5))\n",
    "    if (not test):\n",
    "        print(\"The rate of 'good' movie reviews in the dataset: \")\n",
    "        print(movie_data['sentiment'].mean())\n",
    "\n",
    "    # vectorize Bag of Words from review text; as sparse matrix\n",
    "    if (not test): # fit_transform()\n",
    "        cv = CountVectorizer()\n",
    "        X_cv = cv.fit_transform(movie_data.review)\n",
    "        fitted_transformations.append(cv)\n",
    "        print(\"Shape of CountVectorizer X:\")\n",
    "        print(X_cv.shape)\n",
    "    else: # transform() \n",
    "        X_cv = fitted_transformations[0].transform(movie_data.review)\n",
    "        print(\"Shape of CountVectorizer X:\")\n",
    "        print(X_cv.shape)\n",
    "    \n",
    "    # http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n",
    "    if (not test):\n",
    "        transformer = TfidfTransformer()\n",
    "        X_tfidf = transformer.fit_transform(X_cv)\n",
    "        fitted_transformations.append(transformer)\n",
    "    else:\n",
    "        X_tfidf = fitted_transformations[1].transform(X_cv)\n",
    "    \n",
    "    # create additional quantitative features\n",
    "    # features from Amazon.csv to add to feature set\n",
    "    movie_data['word_count'] = movie_data['review'].str.split(' ').str.len()\n",
    "    movie_data['punc_count'] = movie_data['review'].str.count(\"\\.\")\n",
    "\n",
    "    X_quant_features = movie_data[[\"word_count\", \"punc_count\"]]\n",
    "    print(\"Look at a few rows of the new quantitative features: \")\n",
    "    print(X_quant_features.head(10))\n",
    "    \n",
    "    # Combine all quantitative features into a single sparse matrix\n",
    "    X_quant_features_csr = csr_matrix(X_quant_features)\n",
    "    X_combined = hstack([X_tfidf, X_quant_features_csr])\n",
    "    X_matrix = csr_matrix(X_combined) # convert to sparse matrix\n",
    "    print(\"Size of combined bag of words and new quantitative variables matrix:\")\n",
    "    print(X_matrix.shape)\n",
    "    \n",
    "    # Create `X`, scaled matrix of features\n",
    "    # feature scaling\n",
    "    if (not test):\n",
    "        sc = StandardScaler(with_mean=False)\n",
    "        X = sc.fit_transform(X_matrix)\n",
    "        fitted_transformations.append(sc)\n",
    "        print(X.shape)\n",
    "        y = movie_data['sentiment']\n",
    "    else:\n",
    "        X = fitted_transformations[2].transform(X_matrix)\n",
    "        print(X.shape)\n",
    "    \n",
    "    # Create Training and Test Sets\n",
    "    # enter an integer for the random_state parameter; any integer will work\n",
    "    if (test):\n",
    "        X_submission_test = X\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(movie_data, X_submission_test)\n",
    "    else: \n",
    "        X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = train_test_split(X, y, movie_data, test_size=0.2, random_state=my_random_seed)\n",
    "        print(\"Shape of X_train and X_test:\")\n",
    "        print(X_train.shape)\n",
    "        print(X_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of X_raw_train and X_raw_test:\")\n",
    "        print(X_raw_train.shape)\n",
    "        print(X_raw_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_train, X_test, y_train, y_test, X_raw_train, X_raw_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and test sets from function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_data is: <class 'pandas.core.frame.DataFrame'>\n",
      "movie_data has 25000 rows and 3 columns \n",
      "\n",
      "the data types for each of the columns in movie_data:\n",
      "id           object\n",
      "sentiment     int64\n",
      "review       object\n",
      "dtype: object \n",
      "\n",
      "the first 10 rows in movie_data:\n",
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n",
      "The rate of 'good' movie reviews in the dataset: \n",
      "0.5\n",
      "Shape of CountVectorizer X:\n",
      "(25000, 74849)\n",
      "Look at a few rows of the new quantitative features: \n",
      "   word_count  punc_count\n",
      "0         433          20\n",
      "1         158          16\n",
      "2         378          20\n",
      "3         379           8\n",
      "4         367           9\n",
      "5          89           5\n",
      "6         112           9\n",
      "7         132           9\n",
      "8         163           7\n",
      "9          43           5\n",
      "Size of combined bag of words and new quantitative variables matrix:\n",
      "(25000, 74851)\n",
      "(25000, 74851)\n",
      "Shape of X_train and X_test:\n",
      "(20000, 74851)\n",
      "(5000, 74851)\n",
      "Shape of y_train and y_test:\n",
      "(20000,)\n",
      "(5000,)\n",
      "Shape of X_raw_train and X_raw_test:\n",
      "(20000, 5)\n",
      "(5000, 5)\n",
      "SUCCESS!\n",
      "Number of fits stored in `fitted_transformations` list: \n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# create an empty list to store any use of fit_transform() to transform() later\n",
    "# it is a global list to store model and feature extraction fits\n",
    "fitted_transformations = []\n",
    "\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "X_train, X_test, y_train, y_test, X_raw_train, X_raw_test = process_raw_data(fn='final_data/moviereviews_train.tsv', my_random_seed=68)\n",
    "\n",
    "print(\"Number of fits stored in `fitted_transformations` list: \")\n",
    "print(len(fitted_transformations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit (and tune) Various Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nevenarmanios/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10048, 'Neg': 9952, 'TP': 10001, 'TN': 9931, 'FP': 21, 'FN': 47, 'Accuracy': 0.9966, 'Precision': 0.9979046098583118, 'Recall': 0.9953224522292994, 'desc': 'svm_train_1e-05'}\n",
      "{'Pos': 2452, 'Neg': 2548, 'TP': 2207, 'TN': 2229, 'FP': 319, 'FN': 245, 'Accuracy': 0.8872, 'Precision': 0.8737133808392715, 'Recall': 0.9000815660685155, 'desc': 'svm_test_1e-05'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nevenarmanios/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Pos': 10048, 'Neg': 9952, 'TP': 10048, 'TN': 9952, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'svm_train_0.0001'}\n",
      "{'Pos': 2452, 'Neg': 2548, 'TP': 2179, 'TN': 2188, 'FP': 360, 'FN': 273, 'Accuracy': 0.8734, 'Precision': 0.8582118944466325, 'Recall': 0.8886623164763459, 'desc': 'svm_test_0.0001'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nevenarmanios/anaconda3/lib/python3.11/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "C_values = [\n",
    "    0.00001,\n",
    "    0.0001,\n",
    "    0.001,\n",
    "    0.01,\n",
    "    0.1,\n",
    "    1,\n",
    "    10,\n",
    "    100,\n",
    "    1000,\n",
    "    10_000,\n",
    "    100_000,\n",
    "]\n",
    "fits = []  # Empty list to store all model fits in\n",
    "fits_test = [] \n",
    "\n",
    "\n",
    "for i in C_values:\n",
    "    svm = LinearSVC(random_state = 0, tol = 1e-5, C = i)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    name_training = f\"svm_train_{i}\"  # Give each a unique name\n",
    "    svm_performance_train = BinaryClassificationPerformance(svm.predict(X_train), y_train, name_training)\n",
    "    svm_performance_train.compute_measures()\n",
    "    print(svm_performance_train.performance_measures)\n",
    "    \n",
    "    name_testing = f\"svm_test_{i}\"  # Give each a unique name\n",
    "    svm_performance_test = BinaryClassificationPerformance(svm.predict(X_test), y_test, name_testing)\n",
    "    svm_performance_test.compute_measures()\n",
    "    print(svm_performance_test.performance_measures)\n",
    "    \n",
    "    \n",
    "    fits.append(svm_performance_train)\n",
    "    fits_test.append(svm_performance_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for fit in fits:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: SVM train set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_predictions = svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### let's look at some false positives:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# false positives\n",
    "\n",
    "print(\"Examples of false positives:\")\n",
    "\n",
    "import random, time\n",
    "\n",
    "for i in range(0, len(svm_predictions)):\n",
    "    if (svm_predictions[i] == 1):\n",
    "        if (X_raw_train.iloc[i]['sentiment'] == 0):\n",
    "            if (random.uniform(0, 1) < 0.05): # to print only 5% of the false positives\n",
    "                print(i)\n",
    "                print(X_raw_train.iloc[i]['review'])\n",
    "                print('* * * * * * * * * ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">WARNING: Don't look at test set performance too much!</span>\n",
    "\n",
    "---\n",
    "\n",
    "The following cells show performance on your test set. Do not look at this too often! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look at performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL: SVM, linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fits_test = []\n",
    "\n",
    "# for i in fits:\n",
    "#     svm_performance_test = BinaryClassificationPerformance(i.predict(X_test), y_test, 'svm_test')\n",
    "#     svm_performance_test.compute_measures()\n",
    "#     print(svm_performance_test.performance_measures)\n",
    "#     fits_test.append(svm_performance_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC plot to compare performance of various models and fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fit in fits_test:\n",
    "    plt.plot(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], 'bo')\n",
    "    plt.text(fit.performance_measures['FP'] / fit.performance_measures['Neg'], \n",
    "             fit.performance_measures['TP'] / fit.performance_measures['Pos'], fit.desc)\n",
    "plt.axis([0, 1, 0, 1])\n",
    "plt.title('ROC plot: SVM test set')\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# <span style=\"color:red\">SUBMISSION</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in test data for submission\n",
    "# CHANGE FILE PATH and my_random_seed number (any integer other than 74 will do): \n",
    "raw_data, X_test_submission = process_raw_data(fn='final_data/moviereviews_test.tsv', my_random_seed=68, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 25,000): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Choose a <span style=\"color:red\">*single*</span> model for your submission. In this code, I am choosing the Ordinary Least Squares model fit, which is in the `ols` object. But you should choose the model that is performing the best for you! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the id from the raw data\n",
    "my_submission = pd.DataFrame(raw_data[\"id\"])\n",
    "# concatenate predictions to the id\n",
    "my_submission[\"prediction\"] = svm.predict(X_test_submission)\n",
    "# look at the proportion of positive predictions\n",
    "print(my_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "my_submission.to_csv('final_data/moviereviews_submission_countiningvectorizer_svm.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Canvas: 1) the CSV file that was written in the previous cell and 2) the url to the repository (GitHub or other) that contains your code and documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
